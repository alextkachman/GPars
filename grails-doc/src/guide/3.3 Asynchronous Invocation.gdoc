Running long-lasting tasks in the background belongs to the activities, the need for which arises quite frequently. Your main
thread of execution wants to initialize a few calculations, downloads, searches or such, however, the results may not be needed
immediately. *GPars* gives the developers the tools to schedule the asynchronous activities for processing in the background
and collect the results once they're needed.

h2. Usage of GParsPool and GParsExecutorsPool asynchronous processing facilities

Both _GParsPool_ and _GParsExecutorsPool_ provide almost identical services in this domain, although they leverage different
underlying machinery, based on which of the two classes the user chooses.

h3. Closures enhancements

The following methods are added to closures inside the _GPars(Executors)Pool.withPool()_ blocks:
* async() - Creates an asynchronous variant of the supplied closure, which when invoked returns a future for the potential return value
* callAsync() - Calls a closure in a separate thread supplying the given arguments, returning a future for the potential return value,

Examples:
{code}GParsPool.withPool() {
    Closure longLastingCalculation = {calculate()}
    Closure fastCalculation = longLastingCalculation.async()  //create a new closure, which starts the original closure on a thread pool
    Future result=fastCalculation()                           //returns almost immediately
    //do stuff while calculation performs ...
    println result.get()
}
{code}

{code}
GParsPool.withPool() {
    /**
     * The callAsync() method is an asynchronous variant of the default call() method to invoke a closure.
     * It will return a Future for the result value.
     */
    assert 6 == {it * 2}.call(3)
    assert 6 == {it * 2}.callAsync(3).get()
}
{code}

h4. Timeouts

The _callTimeoutAsync()_ methods, taking either a long value or a Duration instance, allow the user to have the calculation cancelled after a given time interval.

{code}
{->
    while(true) {
        Thread.sleep 1000  //Simulate a bit of interesting calculation
        if (Thread.currentThread().isInterrupted()) break;  //We've been cancelled
    }
}.callTimeoutAsync(2000)
{code}

In order to allow cancellation, the asynchronously running code must keep checking the _interrupted_ flag of its own thread and cease the calculation once the flag is set to true.

h3. Executor Service enhancements

The ExecutorService and jsr166y.forkjoin.ForkJoinPool class is enhanced with the << (leftShift) operator to submit tasks to the pool and return
a _Future_ for the result.

Example:
{code}GParsExecutorsPool.withPool {ExecutorService executorService ->
    executorService << {println 'Inside parallel task'}
}
{code}

h3. Running functions (closures) in parallel

The _GParsPool_ and _GParsExecutorsPool_ classes also provide handy methods _executeAsync()_ and _executeAsyncAndWait()_ to easily run multiple closures asynchronously.

Example:
{code}
GParsPool.withPool {
    assertEquals([10, 20], GParsPool.executeAsyncAndWait({calculateA()}, {calculateB()}))         //waits for results
    assertEquals([10, 20], GParsPool.executeAsync({calculateA()}, {calculateB()})*.get())  //returns Futures instead and doesn't wait for results to be calculated
}
{code}

h3. Parallel speculations

Imagine you need to perform a task like e.g. calculate an expensive function or read data from a file, database or internet. Luckily, you know of several good ways (e.g. functions or urls)
to achieve your goal. However, they are not all equal. Although they return back the same (as far as your needs are concerned) result, they may all take different amount of time to complete
and some of them may even fail (e.g. network issues). What's worse, no-one is going to tell you which path gives you the solution first nor which paths lead to no solution at all. Shall I
run _quick sort_ or _merge sort_ on my list? Which url will work best? Is this service available at its primary location or should I use the backup one?

GPars speculations give you the option to try all the available alternatives in parallel and so get the result from the fastest functional path, silently ignoring the slow or broken ones.

This is what the _speculate()_ methods on _GParsPool_ and _GParsExecutorsPool()_ can do.

{code}
def numbers = ...
def quickSort = ...
def mergeSort = ...
def sortedNumbers = speculate(quickSort, mergeSort)
{code}

Here we're performing both _quick sort_ and _merge sort_ *concurrently*, while getting the result of the faster one. Given the parallel resources available these days on mainstream hardware,
running the two functions in parallel will not have dramatic impact on speed of calculation of either one, and so we get the result in about the same time as if we ran solely the faster of the two
calculations. And we get the result sooner than when running the slower one. Yet we didn't have to know up-front, which of the two sorting algorithms would perform better on our data. Thus
we speculated.

Similarly, downloading a document from multiple sources of different speed and reliability would look like this:

{code}
import static groovyx.gpars.GParsPool.speculate
import static groovyx.gpars.GParsPool.withPool

def alternative1 = {
    'http://www.dzone.com/links/index.html'.toURL().text
}

def alternative2 = {
    'http://www.dzone.com/'.toURL().text
}

def alternative3 = {
    'http://www.dzzzzzone.com/'.toURL().text  //wrong url
}

def alternative4 = {
    'http://dzone.com/'.toURL().text
}

withPool(4) {
    println speculate([alternative1, alternative2, alternative3, alternative4]).contains('groovy')
}
{code}

{note}
Make sure the surrounding thread pool has enough threads to process all alternatives in parallel. The size of the pool should match
the number of closures supplied.
{note}
